{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1JGaEdZBbQwskNygflO23O10F7RXNYu7R",
      "authorship_tag": "ABX9TyN+o121Dm8tMt2uO9/wtlH3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swikriti07/python-libraries-practice/blob/main/Worksheet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#To - Do - 4:\n",
        "Feel free to build your own code or complete the following code:"
      ],
      "metadata": {
        "id": "a2i-zfs9MWzb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1nzCKAISRRQ9"
      },
      "outputs": [],
      "source": [
        "#Define the cost function\n",
        "def cost_function(X, Y, W):\n",
        "  \"\"\" Parameters:\n",
        "  This function finds the Mean Square Error.\n",
        "  Input parameters:\n",
        "  X: Feature Matrix\n",
        "  Y: Target Matrix\n",
        "  W: Weight Matrix\n",
        "  Output Parameters:\n",
        "  cost: accumulated mean square error.\n",
        "  \"\"\"\n",
        "  m=len(Y)\n",
        "  J=np.sum((X.dot(W)-Y)**2)/(2*m)\n",
        "  return J"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#To - Do - 6:\n",
        "Implement your code for Gradient Descent; Either fill the following code or write your own:"
      ],
      "metadata": {
        "id": "MTW73fXOMc96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "  \"\"\"\n",
        "  Perform gradient descent to optimize the parameters of a linear regression model.\n",
        "  Parameters:\n",
        "  X (numpy.ndarray): Feature matrix (m x n).\n",
        "  Y (numpy.ndarray): Target vector (m x 1).\n",
        "  W (numpy.ndarray): Initial guess for parameters (n x 1).\n",
        "  alpha (float): Learning rate.\n",
        "  iterations (int): Number of iterations for gradient descent.\n",
        "  Returns:\n",
        "  tuple: A tuple containing the final optimized parameters (W_update) and the history of cost values\n",
        "  W_update (numpy.ndarray): Updated parameters (n x 1).\n",
        "  cost_history (list): History of cost values over iterations.\n",
        "  \"\"\"\n",
        "  # Initialize cost history\n",
        "  cost_history = [0] * iterations\n",
        "  # Number of samples\n",
        "  m = len(Y)\n",
        "  for iteration in range(iterations):\n",
        "    # Step 1: Hypothesis Values\n",
        "    Y_pred = np.dot(X, W)\n",
        "    # Step 2: Difference between Hypothesis and Actual Y\n",
        "    loss = Y_pred-Y\n",
        "    # Step 3: Gradient Calculation\n",
        "    dw = np.dot(X.T, loss)/m\n",
        "    # Step 4: Updating Values of W using Gradient\n",
        "    W = W - alpha * dw\n",
        "    # Step 5: New Cost Value\n",
        "    cost = cost_function(X, Y, W)\n",
        "    cost_history[iteration] = cost\n",
        "  return W, cost_history"
      ],
      "metadata": {
        "id": "dcd1XiiTVWrT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#To - Do - 8:\n",
        "Implementation of RMSE in the Code - Complete the following code or write your own:"
      ],
      "metadata": {
        "id": "M7v6iAyGMiEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(Y, Y_pred):\n",
        "  \"\"\"\n",
        "  This Function calculates the Root Mean Squres.\n",
        "  Input Arguments:\n",
        "  Y: Array of actual(Target) Dependent Varaibles.\n",
        "  Y_pred: Array of predeicted Dependent Varaibles.\n",
        "  Output Arguments:\n",
        "  rmse: Root Mean Square.\n",
        "  \"\"\"\n",
        "  rmse = np.sqrt(np.sum((Y_pred-Y)**2)/len(Y))\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "AJgInf2PZ4rx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#To - Do - 9 - Implementation in the Code:\n",
        "Complete the following code or write your own for r2 loss:"
      ],
      "metadata": {
        "id": "JHZ3RVKiMpeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation - R2\n",
        "def r2(Y, Y_pred):\n",
        "    \"\"\"\n",
        "    This function calculates the R-squared (R²) score.\n",
        "\n",
        "    Input Arguments:\n",
        "    Y       : Array of actual (target) dependent variables\n",
        "    Y_pred  : Array of predicted dependent variables\n",
        "\n",
        "    Output:\n",
        "    r2      : R-squared value\n",
        "    \"\"\"\n",
        "    mean_y = np.mean(Y)\n",
        "    ss_tot = np.sum((Y - mean_y) ** 2)\n",
        "    ss_res = np.sum((Y - Y_pred) ** 2)\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "    return r2\n"
      ],
      "metadata": {
        "id": "pCMG8LmAa7F3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#• To - Do - 10:\n",
        "We will define a function that:\n",
        "1. Loads the data and splits it into training and test sets.\n",
        "2. Prepares the feature matrix (X) and target vector (Y).\n",
        "3. Defines the weight matrix (W) and initializes the learning rate and number of iterations.\n",
        "4. Calls the gradient descent function to learn the parameters.\n",
        "5. Evaluates the model using RMSE and R2"
      ],
      "metadata": {
        "id": "oKOAZ2MfMvJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def main():\n",
        "    # Step 1: Load the dataset\n",
        "    data = pd.read_csv('/content/drive/MyDrive/DataSet/student.csv')\n",
        "\n",
        "    # Step 2: Split the data into features (X) and target (Y)\n",
        "    X = data[['Math', 'Reading']].values   # Features\n",
        "    Y = data['Writing'].values.reshape(-1, 1)              # Target\n",
        "\n",
        "    # Step 3: Train-test split (80% train, 20% test)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "        X, Y, test_size=0.2, random_state=42\n",
        "    )\n",
        "    Y_train = Y_train.reshape(-1,1)\n",
        "    Y_test = Y_test.reshape(-1,1)\n",
        "    W = np.zeros((X_train.shape[1],1))\n",
        "\n",
        "    # Step 4: Initialize parameters\n",
        "   # W = np.zeros(X_train.shape[1])  # Weights\n",
        "    alpha = 0.00001             # Learning rate\n",
        "    iterations = 1000               # Iterations\n",
        "\n",
        "    # Step 5: Gradient Descent\n",
        "    W_optimal, cost_history = gradient_descent(\n",
        "        X_train, Y_train, W, alpha, iterations\n",
        "    )\n",
        "\n",
        "    # Step 6: Predictions\n",
        "    Y_pred = np.dot(X_test, W_optimal)\n",
        "\n",
        "    # Step 7: Evaluation\n",
        "    model_rmse = rmse(Y_test, Y_pred)\n",
        "    model_r2 = r2(Y_test, Y_pred)\n",
        "\n",
        "    # Step 8: Output results\n",
        "    print(\"Final Weights:\", W_optimal)\n",
        "    print(\"Cost History (First 10 iterations):\", cost_history[:10])\n",
        "    print(\"RMSE on Test Set:\", model_rmse)\n",
        "    print(\"R-Squared on Test Set:\", model_r2)\n",
        "\n",
        "# Execute the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoGBJWuLcUVQ",
        "outputId": "b5236e71-46be-4e11-e560-e5b2ac67e1d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [[0.34811659]\n",
            " [0.64614558]]\n",
            "Cost History (First 10 iterations): [np.float64(2013.165570783755), np.float64(1640.286832599692), np.float64(1337.0619994901585), np.float64(1090.4794892850578), np.float64(889.9583270083234), np.float64(726.8940993009545), np.float64(594.2897260808594), np.float64(486.4552052951635), np.float64(398.7634463599484), np.float64(327.4517147324688)]\n",
            "RMSE on Test Set: 5.2798239764188635\n",
            "R-Squared on Test Set: 0.8886354462786421\n"
          ]
        }
      ]
    }
  ]
}